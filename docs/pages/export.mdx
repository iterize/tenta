# Working with the data

The server stores measurements in the `measurement` table. This table has the following columns:

- **`sensor_identifier`** (`UUID`): The identifier of the sensor that made the measurement.
- **`attribute`** (`TEXT`): The name of the attribute that was measured.
- **`value`** (`DOUBLE PRECISION`): The value of the measurement.
- **`revision`** (`INT`): The revision of the configuration associated with the measurement.
- **`creation_timestamp`** (`TIMESTAMPTZ`): The time at which the measurement was made.
- **`receipt_timestamp`** (`TIMESTAMPTZ`): The time at which the server received the measurement.

The most flexible way to process these measurements further is to download them locally. You can access the database from any programming language and with any PostgreSQL client library.

For Python, the [connector-x](https://github.com/sfu-db/connector-x) and [pyarrow](https://github.com/apache/arrow) libraries are a powerful combination:

```python
import connectorx as cx
import pyarrow.parquet
import pathlib


# Read the data from PostgreSQL (here: our development instance)
table = cx.read_sql(
    conn="postgresql://postgres:12345678@localhost:5432/database",  # PostgreSQL connection string
    query="SELECT * FROM measurement ORDER BY creation_timestamp DESC LIMIT 256",
    return_type="arrow2",
    protocol="binary",
)
# Use the directory of the script as path for the file
path = pathlib.Path(__file__).parent.resolve() / "measurements.parquet"
# Write to parquet file
pyarrow.parquet.write_table(table, where=path)
```

You can then read and process this `parquet` file with your preferred tool, e.g. with [polars](https://github.com/pola-rs/polars):

```python
import pathlib
import polars


# Use the directory of the script as path for the file
path = pathlib.Path(__file__).parent.resolve() / "measurements.parquet"
# Load the parquet file into polars
dataframe = polars.read_parquet(path)
# (optional) Transform the (attribute, value) columns into one column per attribute
dataframe.pivot(
    values='value',
    index=['sensor_identifier', 'revision', 'creation_timestamp'],
    columns='attribute',
    aggregate_function='first',
)
```

You can access the other tables in the same way, e.g. to explore configurations and logs. Please refer to the [database schema](https://github.com/iterize/tenta/blob/main/server/schema.sql) for exact details on the available tables and columns.

If your sensors send their current configuration's revision number with each measurement, you can join the `measurement` and `configuration` tables on `(sensor_identifier, revision)` to match each measurement with the associated configuration.
